# 2025-1-ML

- 전통적 프로그래밍: 규칙으로 데이터 생성
- 머신러닝: 데이터세트로 규칙 생성
- 머신러닝을 사용해야 하는 경우: 규칙이 길고 복잡하고 유지 보수가 잦을 때
- 데이터 마이닝: 인간이 인지 못한 규칙을 발견
- 지도 학습: 데이터에 레이블 있음 - 스팸 필터
- 비지도 학습: 데이터에 레이블 없음 - 계층 군집
- 강화 학습: 데이터 없음
- 온라인 학습: 데이터 수집과 동시에 학습
- 오프라인 또는 배치 학습: 데이터 수집 단계와 학습 단계 분리
- 온라인 학습 과정:
  1. 손실 함수에 모델(식)을 대입한 후 모델의 각 파라미터에 대해 편미분
  2. 각 편미분 함수에 수집한 데이터를 대입하여 기울기 리스트 생성
  3. 기울기 리스트를 최적화 함수에 대입하여 새로운 파라미터 리스트 생성
  4. 파라미터 반영
- 배치 학습 과정:
  1. 손실 함수에 모델(파라미터에 대한 식)을 대입한 후 모델의 각 파라미터에 대해 편미분
  2. 각 편미분 함수에 수집한 데이터를 대입하여 기울기 리스트 생성
  3. 배치의 각 데이터에 대한 기울기 리스트의 평균 생성
  4. 기울기 평균 리스트를 최적화 함수에 대입하여 새로운 파라미터 리스트 생성
  5. 파라미터 반영

> [!note]
> 배치 학습에서는 iii.이 추가됩니다.

> [!note] 
> - 손실 함수의 x축은 모델(파라미터에 대한 식) y축은 오차     
> - 손실 함수의 기울기가 0인 지점을 최소값이라 가정     
> - 현재 모델에서의 손실 함수의 기울기가 클수록 많은 학습이 요구됨을 의미    
> - 기울기를 구할 때 각 파라미터에 대해 편미분을 해서 파라미터별로 요구되는 학습의 벡터(기울기) 산출   
> - 파라미터에 대한 기울기가 양수일 때, 손실 함수의 기울기가 0인 지점에 모델이 가까워지기 위해서는 해당 파라미터를 줄여야 하고 음수일 때에는 해당 파라미터를 키워야 함   
> - 따라서 새로운_파라미터 = 기존_파라미터 + (-(기울기)) * 학습률(하이퍼파라미터)    

- 외부 메모리 학습: 외부 저장소에 데이터를 두고 데이터를 조금씩 읽어와서 반복적으로 모델을 업데이트
- 학습률이 높은 경우: 새로운 데이터에 민감, 예전 데이터의 관성 저하
- 학습률이 낮은 경우: 새로운 데이터에 둔감, 예전 데이터의 관성 증가
- 사례 기반 학습: 예측 단계에서도 학습 데이터가 필요
- 모델 기반 학습: 예측 단계에서 학습 데이터 필요하지 않음

- 머신러닝 파이프라인 주요 단계:
  1. 데이터 수집
  2. 데이터 전처리: 이상치/특이치 탐지
  3. 특성 추출: 쓸모 있는 정보만 추출하여 수치화된 형태로 변환하는 단계
  4. 차원 축소: 특성이 많은 경우, 정보는 유지하면서 변수 수를 줄이는 단계
  5. 시각화 (어떤 단계에서도 활용 가능)
  6. 모델 훈련(학습)
  7. 모델 평가
  8. 실제 응용/예측

- 사이킷런 프로젝트 과정 요약:
  1. 데이터 분석
  2. 모델 선택
  3. 모델 훈련
  4. 예측
 
- 데이터의 중요성: 데이터가 많을수록 성능 증가
- 
