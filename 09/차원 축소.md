차원의 저주: 정확도가 차원의 수에 비례하지 않음
매니폴드 가설: 모든 고차원의 데이터는 저차원의 데이터에 매핑 가능하다

투영projection
예를 들어 3차원 데이터셋에 모든 훈련 샘플이 거의 평면 형태로 놓여 있는 경우
이것이 고차원(3D) 공간에 있는 저차원(2D) 부분 공간subspace
모든 훈련 샘플을 이 부분 공간에 수직으로 (i.e. 샘플과 평면 사이의 가장 짧은 직선을 따라) 투영하면 2D 데이터셋을 얻는다.

스위스 롤: 휘어진 부분 공간

차원 축소 방법
1. 주성분 분석(PCA):
```
from sklearn.decomposition import PCA

pca = PCA(n_components=2)
X2D = pca.fit_transform(X)
```

처음 X가 아래와 같았지만
```
X
array([[-0.47562927 -1.18002627 -0.18665138],
       [-0.32908278  0.18101846 -0.32767249],
       ...,
       [ 0.28072425 -0.21472162  0.43963185]])
```
아래와 같은 두 개의 차원으로 축소됨.
```
X2D
array([[-8.73231190e-01,  2.94598030e-01],
       [ 1.48885182e-01, -5.14935573e-01],
       ...,
       [ 4.54366763e-01,  1.39984497e-01]])
```

이 과정에서 
"정보는 손실되지만, 중복 현상 이외의 데이터(샘플) 손실은 없다."
원래의 거리, 이웃 관계, 패턴 등은 손실될 수 있다.

`1 - pca.explained_variance_ratio_.sum()`의 결과(여기서는 0.09028309326742034)는 구조적·통계적 정보의 손실률을 의미합니다.
이 값은 데이터 샘플(행)의 손실과는 전혀 관련이 없습니다.
PCA는 차원을 줄여도 (중복 현상 등 특별한 경우 제외) 데이터의 샘플 개수(행 수)는 변하지 않습니다.
