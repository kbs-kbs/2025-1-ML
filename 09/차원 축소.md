차원의 저주: 정확도가 차원의 수에 비례하지 않음
매니폴드 가설: 모든 고차원의 데이터는 저차원의 데이터에 매핑 가능하다

투영projection
예를 들어 3차원 데이터셋에 모든 훈련 샘플이 거의 평면 형태로 놓여 있는 경우
이것이 고차원(3D) 공간에 있는 저차원(2D) 부분 공간subspace
모든 훈련 샘플을 이 부분 공간에 수직으로 (i.e. 샘플과 평면 사이의 가장 짧은 직선을 따라) 투영하면 2D 데이터셋을 얻는다.

스위스 롤: 휘어진 부분 공간

차원 축소 방법
1. 주성분 분석(PCA):
```
from sklearn.decomposition import PCA

pca = PCA(n_components=2)
X2D = pca.fit_transform(X)
```

처음 X가 아래와 같았지만
```
X
array([[-0.47562927 -1.18002627 -0.18665138],
       [-0.32908278  0.18101846 -0.32767249],
       ...,
       [ 0.28072425 -0.21472162  0.43963185]])
```
아래와 같은 두 개의 차원으로 축소됨.
```
X2D
array([[-8.73231190e-01,  2.94598030e-01],
       [ 1.48885182e-01, -5.14935573e-01],
       ...,
       [ 4.54366763e-01,  1.39984497e-01]])
```

이 과정에서 
"정보는 손실되지만, 데이터(샘플) 손실은 없다."
원래의 거리, 이웃 관계, 패턴 등의 정보는 손실될 수 있다.
데이터 샘플의 손실은 없고, 손실되는 것은 오직 "고차원 정보(분산, 구조 등)"뿐입니다.
`1 - pca.explained_variance_ratio_.sum()`의 결과(여기서는 0.09028309326742034)는 구조적·통계적 정보의 손실률을 의미합니다.

mnist_784 데이터를 pca하면 784->154개의 차원으로 축소할 수 있어 학습을 최적화시킬 수 있다.


차원축소 기법:
MDS: 이웃데이터와의 거리정보가 보존됨, t-SNE: 이웃데이터와의 거리정보가 손실, 명확한 구분

차원축소를 하면 속도와 정확도가 모두 높아지는 효과가 날 수 있다. 불필요한 차원이 학습에 끼어드는 것을 방지.
